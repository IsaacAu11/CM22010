{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497cbe40",
   "metadata": {},
   "source": [
    "# Coursework: Image Warping\n",
    "### Visual Computing\n",
    "\n",
    "This notebook contains exercises related to image warping, image stitching, non-linear distortions, image morphing, and real-time panorama stitching. Bonus questions are included with specific marks indicated.\n",
    "\n",
    "**Grading Scheme (100 points total)**:\n",
    "\n",
    "- **Affine Transformations**: 10 points\n",
    "- **Homographies**: 10 points\n",
    "- **Projective Transformations**: 10 points\n",
    "- **Non-linear Distortions and Image Stitching**: 15 points\n",
    "- **Image Warping and Interpolation**: 25 points\n",
    "- **Panorama Stitching (Real-Time)**: 15 points\n",
    "- **Image Morphing (Face morphing, scene transitions, etc.)**: 15 points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c969ba6",
   "metadata": {},
   "source": [
    "### 1. Affine Transformations- Recap (10 points)\n",
    "Affine transformations map points between two planes while preserving lines and parallelism, but not necessarily angles. In this task, you will explore how affine transformations can be used to transform an image geometrically.\n",
    "**Task:**\n",
    "- Implement affine transformations to warp an image using a 2x3 transformation matrix.\n",
    "- Apply the transformation matrix to change the geometry of the image, such as rotating, scaling, translating, or shearing.\n",
    "- Visualize the original image and the transformed (warped) image to see how the transformation affects the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Affine Transformations here\n",
    "# Implement the affine transformation function and visualization\n",
    "\n",
    "# Code for Affine Transformations here\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"364547.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "transformation_matrix = np.float32([\n",
    "    [2, 0, 50], \n",
    "    [0, 2, 30]\n",
    "])\n",
    "\n",
    "# Implement the affine transformation function and visualization\n",
    "\n",
    "def apply_affine_transformation(image, transformation_matrix):\n",
    "    shape = image.shape\n",
    "    rows = shape[0]\n",
    "    cols = shape[1]\n",
    "    transformed_image = cv2.warpAffine(image, transformation_matrix, (cols, rows))\n",
    "    return transformed_image\n",
    "\n",
    "transformed_image = apply_affine_transformation(image, transformation_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(transformed_image)\n",
    "plt.title(\"Transformed Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b354c",
   "metadata": {},
   "source": [
    "### 2. Homographies (5 points + 5 Bonus Points)\n",
    "Homographies describe a more complex transformation that maps one plane to another, allowing for perspective effects and changes in shape that still preserve straight lines.\n",
    "\n",
    "**Task:**\n",
    "- Compute the homography matrix between two sets of corresponding points from two images.\n",
    "- Apply the homography matrix to warp one image into the coordinate space of the other.\n",
    "- Use feature detection (like ORB or SIFT) to automatically detect keypoints between the images and align them using the homography.\n",
    "\n",
    "**Bonus Question (5 points):**\n",
    "- Investigate how the number of corresponding points affects the accuracy of the homography. Explore what happens if fewer or more points are used and report your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d314e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image1 = cv2.imread(\"image2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread(\"image3.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(image1, None)\n",
    "kp2, des2 = orb.detectAndCompute(image2, None)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = sorted(bf.match(des1, des2), key=lambda x: x.distance)\n",
    "\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "# Investigate varying numbers of points\n",
    "point_counts = [10, 20, 30, 40, 50, len(src_pts)] \n",
    "warped_images = []\n",
    "\n",
    "for points in point_counts:\n",
    "    indices = np.random.choice(len(src_pts), points, replace=False)\n",
    "    sampled_src_pts = src_pts[indices]\n",
    "    sampled_dst_pts = dst_pts[indices]\n",
    "    H, _ = cv2.findHomography(sampled_src_pts, sampled_dst_pts, cv2.RANSAC)\n",
    "    shape = image2.shape\n",
    "    rows, cols = shape[0], shape[1]\n",
    "    warped_img = cv2.warpPerspective(image1, H, (cols, rows))\n",
    "    warped_images.append((points, warped_img))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.title(\"Original Image 1\")\n",
    "plt.imshow(image1, cmap='gray')\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.title(\"Original Image 2\")\n",
    "plt.imshow(image2, cmap='gray')\n",
    "\n",
    "for i, (count, warped_img) in enumerate(warped_images, start=3):\n",
    "    plt.subplot(3, 3, i)\n",
    "    plt.title(f\"Warped Image with {count} Points\")\n",
    "    plt.imshow(warped_img, cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7229a38",
   "metadata": {},
   "source": [
    "### 3. Projective Transformations (5 points + 5 Bonus Points)\n",
    "Projective transformations allow us to map points from one plane to another, but with perspective distortion. This is commonly used in applications like perspective correction and image warping.\n",
    "\n",
    "**Task:**\n",
    "- Implement a projective transformation matrix and apply it to warp an image.\n",
    "- Use this transformation to warp an image as if it is viewed from a different perspective.\n",
    "- Experiment with multiple projective transformations to create different perspectives and analyze how the image is affected.\n",
    "\n",
    "**Bonus Question (5 points):**\n",
    "- Handle cases where the backward mapping (from the target image back to the source) falls outside the image bounds. Implement strategies like padding, extrapolation, or ignoring out-of-bounds pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Projective Transformations here\n",
    "# Implement projective transformation and handle backward mapping\n",
    "\n",
    "image1 = cv2.imread(\"364547.png\")\n",
    "image1 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "shape = image.shape\n",
    "rows = shape[0]\n",
    "cols = shape[1]\n",
    "\n",
    "transformation_matrix = np.float32([\n",
    "    [0.5, 0.1, cols // 4],\n",
    "    [0.1, 0.5, rows // 4],\n",
    "    [0.001, 0.001, 1]\n",
    "])\n",
    "\n",
    "transformation_matrix_2 = np.float32([\n",
    "    [0, 0.2, 100], \n",
    "    [0, 1, 50],\n",
    "    [0.001, 0.002, 1]\n",
    "])\n",
    "\n",
    "warped_image = cv2.warpPerspective(image, transformation_matrix, (cols, rows))\n",
    "warped_image2 = cv2.warpPerspective(image, transformation_matrix_2, (cols, rows))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Warped Image')\n",
    "plt.imshow(warped_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Warped Image 2')\n",
    "plt.imshow(warped_image2)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de70c9d",
   "metadata": {},
   "source": [
    "### 4. Non-Linear Distortions and Image Stitching (15 points)\n",
    "Non-linear distortions allow you to stretch, compress, or warp an image in non-uniform ways. Image stitching involves aligning multiple images and blending them together to create a larger, seamless composite.\n",
    "\n",
    "**Task:**\n",
    "- Apply non-linear distortions to an image, such as using a fisheye effect or other non-linear transformation.\n",
    "- After experimenting with distortions, move to stitching two or more images together by finding corresponding points, aligning the images using a transformation, and blending them.\n",
    "- For stitching, make sure to use blending techniques (such as linear blending or multi-band blending) to avoid visible seams where the images overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829bf18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Non-Linear Distortions and Image Stitching here\n",
    "#fish eye NL distortion\n",
    "def fishEyeEffect(image, k1, k2):\n",
    "    height, width = image.shape[:2]\n",
    "    center = (width / 2, height / 2)\n",
    "    \n",
    "    y, x = np.indices((height, width))\n",
    "    xNorm = (x - center[0]) / width\n",
    "    yNorm = (y - center[1]) / height\n",
    "\n",
    "    rSq = xNorm**2 + yNorm**2\n",
    "    xDistort = xNorm * (1 + k1 * rSq + k2 * rSq**2)\n",
    "    yDistort = yNorm * (1 + k1 * rSq + k2 * rSq**2)\n",
    "    xMapped = (xDistort * width + center[0]).astype(np.float32)\n",
    "    yMapped = (yDistort * height + center[1]).astype(np.float32)\n",
    "    distorted_image = cv2.remap(image, xMapped, yMapped, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return distorted_image\n",
    "\n",
    "# Apply non-linear distortions and implement image stitching with blending\n",
    "\n",
    "warped_image = fishEyeEffect(image1,k1=0.001, k2=5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('fisheye Image')\n",
    "plt.imshow(warped_image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e13f6b6",
   "metadata": {},
   "source": [
    "### 5. Image Warping and Interpolation (20 points + 5 Bonus Points)\n",
    "When warping images, pixel coordinates often map to non-integer values. Interpolation helps you estimate pixel values at these non-integer coordinates to avoid visual artifacts like pixelation or blurring.\n",
    "\n",
    "**Task:**\n",
    "- Implement nearest-neighbor interpolation to handle sub-pixel coordinates during image warping.\n",
    "- Implement bilinear interpolation, a more advanced method, to provide smoother results.\n",
    "- Compare the results of both interpolation techniques by warping the same image and observing the visual differences.\n",
    "\n",
    "**Bonus Question (5 points):**\n",
    "- How does interpolation affect the quality of stitched or warped images? Analyze how different interpolation methods can impact the final output and report your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Image Warping and Interpolation here\n",
    "# Implement nearest-neighbor and bilinear interpolation and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac57a94",
   "metadata": {},
   "source": [
    "### 6. Panorama Stitching (Real-Time) (15 points)\n",
    "Panorama stitching involves aligning and stitching together multiple images to create a single wide-angle composite. Real-time panorama stitching takes this a step further, allowing for immediate feedback and dynamic composition as more images are added.\n",
    "\n",
    "**Task:**\n",
    "- Implement real-time panorama stitching with multiple images.\n",
    "- Use projective transformations to align images and blend them smoothly.\n",
    "- Ensure that the stitched images have minimal visible seams and apply real-time adjustments as new images are added.\n",
    "\n",
    "**HINT:**\n",
    " You can explore techniques like feathering, linear blending, or multi-band blending for better panaromas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Real-Time Panorama Stitching here\n",
    "# Implement real-time panorama stitching and experiment with blending techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09f8ba",
   "metadata": {},
   "source": [
    "### 7. Image Morphing (Face Morphing, Scene Transitions) (15 points)\n",
    "Image morphing is the process of smoothly transitioning from one image to another by combining both geometric warping and cross-dissolving (blending). Common applications include face morphing and smooth transitions between scenes in videos or graphics.\n",
    "\n",
    "**Task:**\n",
    "- Morph between two faces or two scenes by first geometrically warping the images so that key features align.\n",
    "- Use blending techniques to create a smooth transition from one image to another. Ensure that the transition looks gradual and natural, without sudden jumps or artifacts.\n",
    "- Consider experimenting with intermediate steps to control the pace of the morphing effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Image Morphing here\n",
    "# Implement image morphing between two images with warping and blending"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
